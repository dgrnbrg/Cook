This document tries to capture the new data structure we're considering for the next generation scheduler.

The goals are as follows:

. Support alternative databases besides Datomic
. Enable incremental updates of jobs in order to reduce scheduling latency
. Make it easier to simulate and judge improvements

The basic design is this: the scheduler API will be:

. New job message
. Job status update message
. Request for first N jobs in the queue
. Request for some jobs to preempt
. Timer tick

We'll need several components, which will potentially be internally extensible (to new DBs, etc):

Database Manager::
  Since we're not using Datomic, we'll need a new system to manage the transations and updates to job data.
  The DB protocol needed will be the following:
+
[source,clojure]
----
(defprotocol IDB
  (fetch-by-id [db id] "Returns the job object for the given id")
  (fetch-all-by-job-state [db state] "Returns all job ids for the given job state")
  (fetch-all-by-instance-state [db state] "Returns all job ids for the given instance state")
  (create-job [db id job] "Creates the given job in the DB")
  (update-instance [db id instance] "Creates or updates the given instance of the job"))
----

Job state machine::
  In order to simplify the design of updating instances, reconciliation, and failover, we're going to make the instance state machines be eventually consistent.
  Instances have 4 states: *unknown*, *running*, *succeeded*, *failed*, *killed*.
  In that order, the latter state wins in the merge.
  This way, a spurious success is correctly marked failure, and a failure due to being killed is marked as killed in case a spurious LOST appeared first.


Per-user queue::
  Each user will have an in-memory sorted map of their jobs.
  The keys of the map will be the job ids, and the values will be the following record:
+
[source,clojure]
----
(defrecord JobSummary [id, ^double cpus, ^double mem, ^int priority, ^long submit-time])
----
+
The map must be sorted by the `priority` field of the `JobSummary`, tiebreaking on the `submit-time`.
This way, it's lg(N) to insert, update, or remove a single job.
It's also easy to do the merge step of a mergesort to compute the first N jobs in the queue overall, by computing the DRF as we go.
+
Each queue must also store the total demanded CPU and memory in order to perform preemption.
To do a rebalance operation, we first compute how many resources should each user have, in total.
This is easy to do, by calculating the fair share per user, and redistributing the residual to the users with remaining demand until all users are satisfied or all resources are used.
Next, we separate the jobs for each user into those which should be waiting and those which should be running.
Since the jobs are stored in priority order, and we can easily find the set of jobs which should be running (by consuming from the head of the queue), we can thus split every users' jobs into those waiting and those running.
Next, we filter the jobs so that we only consider waiting jobs which should be running, and running jobs which should be waiting.
We can feed these 2 sets to the <<preemption_heuristic,preemption heuristic>> in order to get a decision on what action to take.

Simulation::
  We'll have time progress through a single timer channel; this will make it much easier to write a simulator.

Task placement::
  We'll use the already-created fenzo/backfill system for task placement.
  We'll probably need to add backfilled jobs duplicated to the user queues, so that they exist both at the front part (for being upgraded) and the rear part (for being preempted).
  This will allow us to maintain the single sorted map, rather than a pair of them.

[[preemption_heuristic]]
=== Proposal for heuristic preemption solver

Here's a proposal that might work for a preemption solver:
the idea is to formulate the preemption problem as an integer program, solve it as a linear program, convert it back to an integer solution, and then use local search to improve.

Integer program formulation::
  We'll have 2 sets of variables: `running_i` and `pending_i`.
  `running_i` represents each of the currently running jobs; they're 1 if the job `i` is preempted, 0 otherwise.
  `pending_jh` represents each of the currently pending jobs; they're 1 if job `j` starts running on host `h`, 0 otherwise.
  We have a list of constants `cpu_ih` and `mem_ih`, which is the usage of CPU and memory by job `i` on host `h`.
  Our goal is to maximize the sum over all `j` and `h` of `pending_jh`.
  Our constraints are:
+
. All `running_i` and `pending_jh` are either 0 or 1
. For each `j`, the sum over all `h` of `pending_jh` must be less than 1.
. For each `h`, the sum for all `i` of `running_i * cpu_ih` minus `pending_j * cpu_jh` must be positive.
. The same rule as above, but also for CPUs.

Linear program solver::
  We then solve the above integer program as a linear program, getting values between zero and one for every job.
  We'll treat those as probabilities for that job's value being 0 or 1.
  Thus, we use those to weight the probabilities of jobs, and we can come up with as many random (feasible and infeasible) assignments as we'd like.
  We'll filter these assignment for feasibility, only passing feasible solutions to the next step.
  We can, in parallel, compute many feasible solutions, which can be improved by local search in parallel as well.

Local search improvement::
  We can use simulated annealing to further improve the solutions.
  It seems unlikely that genetic programming will help, since we're just improving the LP relaxation, which won't have many different solutions.
  This local search is also easily parallelized.
